---
name: Innovation
description: Task: Innovation. Use this prompt when exploring meaningful structural or interaction innovations under controlled constraints.
---

## Goal

Develop meaningful innovation that increases understanding of uncertainty and orientation.

Innovation must:

- improve clarity
- strengthen interpretive guidance
- remain structurally disciplined

This is a controlled refinement phase.

---

## Anchor: Binding Rules (Do not restate — enforce)

All work in this iteration must comply with the **Innovation & Interaction Design** and **Data Authority & Dataset Integrity (MANDATORY)** section and general practices in `copilot-instructions.md` and must remain consistent with the project’s conceptual framework in `Dok/Visualization Context & Framework.md`, specifically:

- In `copilot-instructions.md`:
  - **Innovation & Interaction Design**
  - **Data Authority & Dataset Integrity (MANDATORY)**
  - **Start, Stable vs Test Environment (ARCHITECTURE RULE)**

- In `Dok/Visualization Context & Framework.md`:
  - The visualization’s role as a journalistic explanatory tool
  - The scenario-card landscape concept (consistency and comparability across tasks/states)
  - The fixed task structure (Task 1–3) as the interpretive framework

---

## Scope

This iteration focuses on structural and interaction innovation.

You are allowed to:

- Propose new layout structures
- Propose new interaction flows (e.g. smooth resorting, contextual fading, soft focus / focus shift etc, Scroll-triggered emphasis)
- Introduce comparative mechanics
- Reorganize spatial logic

---

## When to Introduce Test Variants

Innovation always requires structural comparison.

If proposing innovation:

- Present at least two clearly differentiated structural concepts.
- Define each as a selectable variant in the test variant system.
- Clearly specify constants and differences.
- Do not implement until approval.

Do not generate cosmetic variants.

---

## Procedure (Do not implement yet)

### Step 1 — Baseline Diagnosis

Identify:

- Template-like elements
- Orientation weaknesses
- Underused interaction potential

---

### Step 2 — Innovation Proposals

For each concept:

- Structural idea
- Interaction logic
- Interpretive benefit
- What remains unchanged
- Technical implications
- Risk profile

---

### Step 3 — Comparative Evaluation

Score each concept on:

- Structural clarity
- Interaction intuitiveness
- Innovative character
- Technical feasibility
- Regression risk

---

## Definition of Done

The iteration is successful when:

- At least two structurally distinct innovation concepts exist
- Both are selectable in the test variant system
- No data logic changes occurred
- Risk is transparently assessed
- One concept is recommended for implementation

---

## Pre-Check

Before implementation, output:

1. Baseline diagnosis
2. Innovation concepts
3. Comparative evaluation
4. Recommendation

Then ask:

“Do you approve implementing the selected innovation concept in the test environment via the test variant system?”

Wait for explicit approval.
